{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "# plotting imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ml imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# k nearest neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# metric imports\n",
    "\n",
    "# cnn imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "sys.path.append('../')\n",
    "from model import model3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cancer dataset from sklearn\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "# randomly rearrange data\n",
    "random_state = 42\n",
    "np.random.seed(random_state)\n",
    "indices = np.random.permutation(len(X))\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# split data\n",
    "test_size = 0.2\n",
    "train_size = 1 - test_size\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"cancer\"\n",
    "repeat = 5\n",
    "datetime = dt.datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "data_sizes = [50, 100, 500, 1000, None]\n",
    "benchmarking = {}\n",
    "info_length = 3 # train_acc, test_acc, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, model_name, data_size, info_type, iteration, val=False):\n",
    "    train = \"train\" if not val else \"val\"\n",
    "    path = f\"results/{dataset_name}/{model_name}/npy_files/d{data_size}_{train}_{info_type}_i{iteration}_d{datetime}.npy\"\n",
    "    np.save(path, data)\n",
    "\n",
    "def load_data(model_name, data_size, info_type, iteration, val=False):\n",
    "    train = \"train\" if not val else \"val\"\n",
    "    date_format = \"%Y%m%d_%H%M\"\n",
    "    dir = f\"results/{dataset_name}/{model_name}/npy_files\"#d{data_size}_{train}_{info_type}_i{iteration}_d{datetime}.npy\"\n",
    "    partial_name = f\"d{data_size}_{train}_{info_type}_i{iteration}\"\n",
    "\n",
    "    # get all the datetimes\n",
    "    datetimes = [name.split(\"_\")[-1].split(\".\")[0] for name in os.listdir(dir) if partial_name in name]\n",
    "    # get the latest datetime by converting to datetime object\n",
    "    latest_datetime = max([dt.datetime.strptime(date, date_format) for date in datetimes]).strftime(date_format)\n",
    "    path = os.path.join(dir, f\"{partial_name}_d{latest_datetime}.npy\")\n",
    "    try:\n",
    "        return np.load(path)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_ml(model_name):\n",
    "    \"\"\"\n",
    "    Trains a model on the cancer dataset with different data sizes and saves the accuracy and time data.\n",
    "\n",
    "    Parameters:\n",
    "    model_name (str): The name of the model to train. Can be \"randomforest\", \"knn\", or \"ours\".\n",
    "\n",
    "    Returns:\n",
    "    results_dict (dict): A dictionary containing the accuracy and time data for each model and iteration\n",
    "    \"\"\"\n",
    "    model = RandomForestClassifier(n_jobs=-1) if model_name == \"randomforest\" else \\\n",
    "            KNeighborsClassifier(n_jobs=-1) if model_name == \"knn\" else \\\n",
    "            model3() if model_name == \"ours\" else None\n",
    "    results_dict = {model_name: {}}\n",
    "    \n",
    "    progress = tqdm(total=repeat*len(data_sizes), desc=f\"Benchmarking {model_name}\")\n",
    "    for i in range(repeat):\n",
    "        time_list = []\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "\n",
    "        for size in data_sizes:\n",
    "            if size is None:\n",
    "                size = len(X_train)\n",
    "            # train model\n",
    "            start_time = time.perf_counter()\n",
    "            clf = model\n",
    "            clf.fit(X_train[:size], y_train[:size])\n",
    "            y_pred = clf.predict(X_test)\n",
    "            end_time = time.perf_counter()\n",
    "\n",
    "            # predict and compute accuracy\n",
    "            y_pred_train = clf.predict(X_train[:size])\n",
    "            y_pred = clf.predict(X_test)\n",
    "            acc_train = accuracy_score(y_train[:size], y_pred_train)\n",
    "            acc_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "            # update lists\n",
    "            time_list.append(end_time - start_time)\n",
    "            train_acc.append(acc_train)\n",
    "            val_acc.append(acc_test)\n",
    "            progress.update(1)\n",
    "\n",
    "        # save data\n",
    "        train_acc = np.array(train_acc)\n",
    "        val_acc = np.array(val_acc)\n",
    "        time_list = np.array(time_list)\n",
    "        save_data(train_acc, model_name, size, \"acc\", i)\n",
    "        save_data(val_acc, model_name, size, \"acc\", i, val=True)\n",
    "        save_data(time_list, model_name, size, \"time\", i)\n",
    "        results_dict[model_name][i] = {\"train_acc\": train_acc, \"val_acc\": val_acc, \"time\": time_list}\n",
    "    progress.close()\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Random Forest does not use epochs and does not compute loss so we are missing\n",
    "train_loss\n",
    "val_loss\n",
    "\"\"\"\n",
    "model_name = 'randomforest'\n",
    "rfr_results = benchmark_ml(model_name)\n",
    "benchmarking[model_name] = rfr_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "K Nearest Neighbors does not use epochs and does not compute loss so we are missing\n",
    "train_loss\n",
    "val_loss\n",
    "\"\"\"\n",
    "model_name = 'knn'\n",
    "knn_results = benchmark_ml(model_name)\n",
    "benchmarking[model_name] = knn_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'cnn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'metric'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Our model does not use epochs and does not compute loss so we are missing\n",
    "train_loss\n",
    "val_loss\n",
    "\"\"\"\n",
    "model_name = 'ours'\n",
    "our_results = benchmark_ml(model_name)\n",
    "benchmarking[model_name] = our_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "for model_name, model_results in benchmarking.items():\n",
    "    for iteration, iteration_results in model_results.items():\n",
    "        for i, info_type, info in enumerate(iteration_results.items()):\n",
    "            plt.subplot(info_length, 1, i+1)\n",
    "            plt.plot(data_sizes, info, label=f\"{model_name}_i{iteration}\")\n",
    "            plt.xlabel(\"Data Size\")\n",
    "            plt.ylabel(info_type)\n",
    "            plt.legend()\n",
    "plt.title(\"Model Benchmarking\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"results/{dataset_name}/charts/benchmarking_{datetime}.png\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
